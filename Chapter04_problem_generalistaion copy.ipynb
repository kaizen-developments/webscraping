{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem: Parse the title and body of the websites Brookings and NYTimes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the getter functions!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getPage(url):\n",
    "    req = requests.get(url)\n",
    "    return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "def getTextOfFirstTagMatchedInSoup(searchPattern, bs, property = \"tag\"):\n",
    "    try:\n",
    "        title = bs.find(**searchPattern).text\n",
    "    except AttributeError as e:\n",
    "        print(f\"An attempt was made to access the text of the assumed to be {property}, None was accessed.\")\n",
    "        return ''\n",
    "    return title\n",
    "\n",
    "def getTextOfSecondTagMatchedInSoup(searchPattern, bs, property = \"tag\"):\n",
    "    try:\n",
    "        titles = bs.find_all(**searchPattern)\n",
    "        title = titles[0].text\n",
    "    except IndexError as e:\n",
    "        print(f\"The title tags can be indexed atmost by {len(titles)-1}, current index is {1}!\")\n",
    "        return ''\n",
    "    except AttributeError as e:\n",
    "        print(f\"An attempt was made to access the text of the assumed to be {property}, None was accessed.\")\n",
    "        return ''\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the classes to be used!\n",
    "\n",
    "class Content:\n",
    "    def __init__(self, url = \"\", title = \"\", body = \"\"):\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "    def __str__(self):\n",
    "        return 'Title: {}'.format(self.title) + \"\\n\" + ('URL: {}\\n'.format(self.url)) + \"\\n\" + (self.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the types being used!\n",
    "from typing import Callable, Tuple, Dict, List\n",
    "\n",
    "\n",
    "Pattern = dict\n",
    "Url = str\n",
    "Title = str \n",
    "Body = str\n",
    "Strategy = Callable\n",
    "Strategies = Dict[str, Strategy]\n",
    "Patterns = Dict[str, Pattern]\n",
    "Component = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an abstract class for checking whether the dataModel has a default value or not!\n",
    "\n",
    "\n",
    "import abc\n",
    "import inspect\n",
    "from typing import Type\n",
    "\n",
    "\n",
    "class TypeWithADefaultValue(abc.ABC):\n",
    "    def __init_subclass__(cls, **kwargs):\n",
    "        super().__init_subclass__(**kwargs)\n",
    "        cls._check_init_defaults()\n",
    "\n",
    "    @classmethod\n",
    "    def _check_init_defaults(cls):\n",
    "        init_signature = inspect.signature(cls.__init__)\n",
    "        for name, param in init_signature.parameters.items():\n",
    "            if name == 'self':\n",
    "                continue\n",
    "            if param.default is inspect.Parameter.empty:\n",
    "                raise TypeError(f\"Parameter '{name}' in {cls.__name__}.__init__ must have a default value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define how to obtain the components of a class with a default value!\n",
    "def componentsOf(dataModel : type): #TODO: Test whether base class has default value or not\n",
    "    #if not issubclass(dataModel, TypeWithADefaultValue):\n",
    "    #    raise TypeError(\"The dataModel does not have a default value.\")\n",
    "    return list(dataModel().__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the general function from which the scraper for each individual website will be created based on the classes to be used!\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def scrapeWebsiteForComponentsOfDataModel(url : Url, patterns : Patterns, strategies : Strategies, dataModel : type):\n",
    "    dataModelParameters = tuple()\n",
    "    for component in componentsOf(dataModel):\n",
    "        dataModelParameters = strategies[component](url, patterns[component])\n",
    "    return dataModel(*dataModelParameters)\n",
    "\n",
    "#Generalized from:\n",
    "#def scrapeWebsiteForTitleAndBody(url, patterns : Patterns, strategies : Strategies):\n",
    "#\n",
    "#    title = strategies[\"title\"](url, patterns[\"title\"])\n",
    "#    body = strategies['body'](url, patterns['body'])\n",
    "#\n",
    "#    return Content(url, title, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the classes to be used create the function determining what data to look for on the websites!\n",
    "\n",
    "#scrapeWebsiteForTitleAndBody = partial(scrapeWebsiteForComponentsOfDataModel, dataModel = Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the strategies to choose from!\n",
    "\n",
    "def searchForTextOfFirstMatch(url : Url, pattern : Pattern):\n",
    "    bs = getPage(url)\n",
    "    tag = getTextOfFirstTagMatchedInSoup(pattern, bs)\n",
    "    return tag\n",
    "\n",
    "def searchForTagByParts(url, pattern : Pattern):\n",
    "    tags = getPage(url).find_all(**pattern)\n",
    "    goalTag = ''\n",
    "    for tag in tags:\n",
    "        goalTag += (tag.text) + \"\\n\"\n",
    "    return goalTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the websites!\n",
    "domains = [\"brookings.edu\", \"nytimes.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the strategies to use for the websites!\n",
    "BrookingsStrategy = {\n",
    "    \"title\" : searchForTextOfFirstMatch, \n",
    "    \"body\"  : searchForTagByParts\n",
    "    }\n",
    "\n",
    "NYTimesStrategy = {\n",
    "    \"title\" : searchForTextOfFirstMatch,\n",
    "    \"body\" : searchForTagByParts\n",
    "}\n",
    "websiteStrategies = {\n",
    "    \"brookings.edu\"  : BrookingsStrategy,\n",
    "    \"nytimes.com\"   :NYTimesStrategy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the patterns for the scrapers!\n",
    "\n",
    "BrookingsPatterns = {\n",
    "    \"title\" : {'name' : 'title'},\n",
    "    \"body\"  : {'name' : 'div', 'attrs' : {'class' : \"byo-block -narrow wysiwyg-block wysiwyg\"}}\n",
    "}\n",
    "\n",
    "NYTimesPatterns = {\n",
    "    \"title\" : {'name' : 'title'},\n",
    "    \"body\"  : {'selector' : ('div.StoryBodyCompanionColumn div p')}\n",
    "}\n",
    "patterns = {\n",
    "    \"brookings.edu\" : BrookingsPatterns,\n",
    "    \"nytimes.com\"   : NYTimesPatterns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5704cbf6235f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"nytimes.com\"\u001b[0m   \u001b[0;34m:\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapeWebsiteForTitleAndBody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrookingsStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNYTimesPatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscrapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"brookings.edu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-756fc7ee13c5>\u001b[0m in \u001b[0;36mscrapeWebsiteForComponentsOfDataModel\u001b[0;34m(url, patterns, strategies, dataModel)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdataModelParameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponentsOf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdataModelParameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataModelParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'url'"
     ]
    }
   ],
   "source": [
    "#Define the scrapers for all websites to be parsed using the known data to look for, the patterns, and the strategies!\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "scrapers = {\n",
    "    \"brookings.edu\" : partial(scrapeWebsiteForTitleAndBody,strategies = BrookingsStrategy, patterns = BrookingsPatterns),\n",
    "    \"nytimes.com\"   : partial(scrapeWebsiteForTitleAndBody, strategies = BrookingsStrategy, patterns = NYTimesPatterns)\n",
    "}\n",
    "scrapers[\"brookings.edu\"]('https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a regex pattern for finding the domain of a website!\n",
    "import re\n",
    "def findDomainOf(url):\n",
    "    match = re.search(r'https?:\\/\\/(?:www\\.)?([^\\/:]+)', url)\n",
    "    if match:\n",
    "        domain = match.group(1)\n",
    "        return domain \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define printing of url's based on their website \n",
    "\n",
    "# #Strategies:\n",
    "# #Define the strategies to use for the websites!\n",
    "# BrookingsStrategy = {\n",
    "#     \"title\" : searchForTextOfFirstMatch, \n",
    "#     \"body\"  : searchForTagByParts\n",
    "#     }\n",
    "\n",
    "# NYTimesStrategy = {\n",
    "#     \"title\" : searchForTextOfFirstMatch,\n",
    "#     \"body\" : searchForTagByParts\n",
    "# }\n",
    "# websiteStrategies = {\n",
    "#     \"brookings.edu\"  : BrookingsStrategy,\n",
    "#     \"nytimes.com\"   :   NYTimesStrategy\n",
    "# }\n",
    "\n",
    "# #Patterns:\n",
    "\n",
    "# BrookingsPatterns = {\n",
    "#     \"title\" : {'name' : 'title'},\n",
    "#     \"body\"  : {'name' : 'div', 'attrs' : {'class' : \"byo-block -narrow wysiwyg-block wysiwyg\"}}\n",
    "# }\n",
    "\n",
    "# NYTimesPatterns = {\n",
    "#     \"title\" : {'name' : 'title'},\n",
    "#     \"body\"  : {'selector' : ('div.StoryBodyCompanionColumn div p')}\n",
    "# }\n",
    "# patterns = {\n",
    "#     \"brookings.edu\" : BrookingsPatterns,\n",
    "#     \"nytimes.com\"   : NYTimesPatterns\n",
    "# }\n",
    "\n",
    "# def scrapeUrlBasedOnASingleDataModelAndStrategiesAndPatternsForWebsites(url : Url, dataModel : type, websiteStrategies : Strategies, patterns : Patterns, domains : List[Url]):\n",
    "#     scrapeWebsiteForTheDataModel = partial(scrapeWebsiteForComponentsOfDataModel, dataModel = dataModel)\n",
    "#     scrapers = {domain : partial(scrapeWebsiteForTheDataModel, patterns = patterns[domain], strategies = websiteStrategies[domain]) for domain in domains}\n",
    "#     domain = findDomainOf(url)\n",
    "#     return scrapers[domain](url)\n",
    "\n",
    "# scrapeWebsiteForTitleAndBody = partial(scrapeUrlBasedOnASingleDataModelAndStrategiesAndPatternsForWebsites, dataModel = Content, websiteStrategies = websiteStrategies, patterns = patterns, domains = domains)\n",
    "# print(scrapeWebsiteForTitleAndBody('https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/'))\n",
    "\n",
    "# #TODO: Find the website from the link!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scrapeUrlBasedOnASingleDataModelAndStrategiesAndPatternsForWebsites() got an unexpected keyword argument 'strategies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bbef6aa131b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint_the_content_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint_the_content_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.brookings.edu/articles/the-hamilton-project-2023-in-figures/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint_the_content_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.brookings.edu/articles/bill-baers-testimony-before-the-u-s-senate-committee-on-the-judiciary-subcommittee-on-competition-policy-antitrust-and-consumer-rights/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-bbef6aa131b1>\u001b[0m in \u001b[0;36mprint_the_content_of\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_the_content_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScrapeTitleAndBodyOf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-bbef6aa131b1>\u001b[0m in \u001b[0;36mScrapeTitleAndBodyOf\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mScrapeTitleAndBodyOf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindDomainOf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscrapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_the_content_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scrapeUrlBasedOnASingleDataModelAndStrategiesAndPatternsForWebsites() got an unexpected keyword argument 'strategies'"
     ]
    }
   ],
   "source": [
    "#Print the contents!\n",
    "def ScrapeTitleAndBodyOf(url):\n",
    "    domain = findDomainOf(url)\n",
    "    return scrapers[domain](url)\n",
    "\n",
    "def print_the_content_of(url):\n",
    "    data = ScrapeTitleAndBodyOf(url)\n",
    "    print(data)\n",
    "\n",
    "print_the_content_of('https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/')\n",
    "print_the_content_of(\"https://www.brookings.edu/articles/the-hamilton-project-2023-in-figures/\")\n",
    "print_the_content_of(\"https://www.brookings.edu/articles/bill-baers-testimony-before-the-u-s-senate-committee-on-the-judiciary-subcommittee-on-competition-policy-antitrust-and-consumer-rights/\")\n",
    "print_the_content_of('https://www.nytimes.com/2018/01/25/opinion/sunday/silicon-valley-immortality.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the following code work\n",
    "class Scraper1:\n",
    "    def __init__(self, dataModel):\n",
    "        self.dataModel\n",
    "    \n",
    "    def modifyStrategy(self, website, dataComponent, newStrategy)\n",
    "\n",
    "scraper.modifyStrategy(website, dataComponent, newStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
