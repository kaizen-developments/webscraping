{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urllib is a standard Python library, containing functions for\n",
    "1. requesting data across the web, \n",
    "2. handling cookies, \n",
    "3. changin metadata, such as headers and your user agent.\n",
    "\n",
    "Documentation for urllib is https://docs.python.org/3/library/urllib.html\n",
    "\n",
    "the function named \"urlopen\" is used to open a remote object across a network and read it.\n",
    "urlopen is a function of urllib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "#Tell the processor to send data to the application that handles your wireless (or wired) interface!\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#Obtain the resource\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "#The same code but with added abstraction by myself, considering html file to be a resource, having an address, and urlopen beinga a method to use to obtain the \n",
    "#resource from the address!\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def obtain_resource_with(address_or_id_of_the_resource : str, method_used_to_obtain_the_resource : callable):\n",
    "    return method_used_to_obtain_the_resource(address_or_id_of_the_resource)\n",
    "\n",
    "address_of_the_resource = 'http://pythonscraping.com/pages/page1.html'\n",
    "method_used_to_obtain_the_resource = urlopen\n",
    "\n",
    "resource = obtain_resource_with(address_of_the_resource, method_used_to_obtain_the_resource)\n",
    "\n",
    "print(resource.read())\n",
    "\n",
    "assert(resource.read() == html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n",
      "True\n",
      "None\n",
      "'NoneType' object has no attribute 'someTag'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-3db1a7e72b11>:20: DeprecationWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead. If you really were looking for a tag called nonExistentTag, use .find(\"nonExistentTag\")\n",
      "  print(bs.nonExistentTag)\n",
      "<ipython-input-20-3db1a7e72b11>:23: DeprecationWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead. If you really were looking for a tag called nonExistentTag, use .find(\"nonExistentTag\")\n",
      "  print(bs.nonExistentTag.someTag)\n"
     ]
    }
   ],
   "source": [
    "#Get the HTML content of the page and create a BeautifulSoup object!\n",
    "    #Find a name for the BeautifulSoup object and start an assignment expression with the name!\n",
    "    #Start writing the constructor of the BeautifulSoup object!\n",
    "    #Pass to the constructor the HTML text the object is based on!\n",
    "    #Pass to the constructor the specification of the parser for BeautifulSoup to use!\n",
    "    #Finish writing the constructor!\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Obtain the html file!\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "#Print the first instance of the tag h1!\n",
    "print(bs.h1)\n",
    "\n",
    "print(bs.h1 == bs.html.body.h1 == bs.body.h1 == bs.body.h1 == bs.html.h1)\n",
    "\n",
    "print(bs.nonExistentTag)\n",
    "\n",
    "try:\n",
    "    print(bs.nonExistentTag.someTag)\n",
    "except AttributeError as ae:\n",
    "    print(\"\\'NoneType\\' object has no attribute \\'someTag\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server could not be found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://pythonscrapingthisurldoesnotexist.com\")\n",
    "except HTTPError as e: #The rest of the program given an HTTPError, not being executed.\n",
    "    print(\"The server returned an HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether no server could be reached at all!\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "#Try to open the website, except when HTTPError or ERLError occurs, in the later case print the indicator of the error!\n",
    "try:\n",
    "    html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('The server could not be found!')\n",
    "else:\n",
    "    print('It Worked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalization\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "#Try to open the website, except when HTTPError or URLError occurs, in the later case print the indicator of the error!\n",
    "def initialize_html_safely(address : str):\n",
    "    try:\n",
    "        html = urlopen(address)\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "    except URLError as e:\n",
    "        print('The server could not be found!')\n",
    "    else:\n",
    "        print('Html initialized safely!')\n",
    "        return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guard against a bs object having or not having a tag!\n",
    "\n",
    "\n",
    "try:\n",
    "    badContent = bs.nonExistingTag.anotherTag\n",
    "except AttributeError as e:\n",
    "    print('Tag was not found')\n",
    "else:\n",
    "    an_attempt_was_made_to_access_a_non_existent_tag = badContent == None\n",
    "    if an_attempt_was_made_to_access_a_non_existent_tag:\n",
    "        print ('Tag was not found')\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        #Encapsulate two of the BeautifulSoup lines inside one try statement!\n",
    "        #Constraint: A line of code exists between the \"try:\" and \"except AttributeError as e:\" keywords implies that the execution of the line might throw an AttributeError.\n",
    "        bsObj = BeautifulSoup(html.read(), \"lxml\")\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
